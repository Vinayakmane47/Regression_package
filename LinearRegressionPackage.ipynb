{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed8aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.formula.api as sm \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge,Lasso,RidgeCV,LassoCV,ElasticNet,ElasticNetCV,LinearRegression\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Eda_vinu: \n",
    "    '''\n",
    "    Thid module helps the user for doing Exploratory data analysis by calling some sort of functions\n",
    "    '''\n",
    "    def make_frame(self,file_location): \n",
    "        \"\"\"Make Dataframe from given file input \n",
    "        ====================================================\n",
    "        file_location : Path of file \n",
    "        \"\"\"\n",
    "        try : \n",
    "            df = pd.read_csv(r\"{}\".format(file_location))\n",
    "            return df \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(make_frame)- failed to make a frame.\\n\" + str(e))\n",
    "            \n",
    "    \n",
    "    def null_val_summary(self,df): \n",
    "        \"\"\"Make a Summary of null values of dataframe \n",
    "        =============================================\n",
    "        df : Data \n",
    "        file location : Path of file \n",
    "        \"\"\"\n",
    "        try : \n",
    "            summary = df.isnull().sum()\n",
    "            return summary \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(null_val_summary) - failed to create summary of null values.\\n\" + str(e))\n",
    "            \n",
    "    def profile_report_to_widgets(self,df): \n",
    "        \n",
    "        \"\"\" Create a pandas profile widget \n",
    "        ================================================\n",
    "        df : Data\n",
    "        \n",
    "        \"\"\"\n",
    "        try : \n",
    "            report = ProfileReport(df,title=\"Pandas Profile Report\")\n",
    "            return report.to_widgets()\n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(profile_report_to_widgets) - failed to craete pandas profile report.\\n\" + str(e))\n",
    "            \n",
    "            \n",
    "    def profile_report_to_notebook_iframe(self,df): \n",
    "        \n",
    "        \"\"\" Create a notebook iframe report using dataframe \n",
    "        =======================================================\n",
    "        df : Data\n",
    "        \"\"\"\n",
    "        try : \n",
    "            report = ProfileReport(df)\n",
    "            return report.to_notebook_iframe()\n",
    "        \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(profile_report_to_notebook_iframe) - failed to create notebook iframe.\\n\" + str(e))\n",
    "            \n",
    "    def unwanted_index_col(self,df):\n",
    "        \n",
    "        \"\"\" Remove unwanted index columns which do not required for training purpose\n",
    "           This function Automatically finds out and drop  the column which is indexed as seriel number\n",
    "        ===========================================================================================\n",
    "        df : Data\n",
    "        \"\"\"\n",
    "       \n",
    "        try : \n",
    "            import copy \n",
    "            df1 = copy.deepcopy(df)\n",
    "            for j in range(df.shape[1]):\n",
    "                var  =False\n",
    "                a = list(df1.iloc[:,j] )\n",
    "                for i in range(1,len(a)+1): \n",
    "                    if a[i-1] == i : \n",
    "                        pass\n",
    "                    else : \n",
    "                        #print(\"not match\")\n",
    "                        var = True\n",
    "                        break \n",
    "                if var == False : \n",
    "                    #print(\"required\")\n",
    "                    df.drop(columns=[df1.columns[j]],inplace=True)\n",
    "                    \n",
    "            return True \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(unwanted_index_col) - failed to remove columns.\\n\" + str(e))\n",
    "            \n",
    "    def float_int_cols(self,df): \n",
    "        \"\"\"This Dataframe contains only contains columns having  Float and Int datatypes\n",
    "        this is usefull for doing regression on data \n",
    "        ======================================================================================\n",
    "        Input : \n",
    "            df --> Data\n",
    "        Output : \n",
    "            df --> Dataframe with only int and float columns \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            df1 = df[df.dtypes[(df.dtypes != object )].index]\n",
    "            return df1 \n",
    "        \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(float_int_cols) - failed to return required dataframe.\\n\" + str(e))\n",
    "            \n",
    "            \n",
    "    def remove_null_val(self,cd,df): \n",
    "        \"\"\" This function checks if there are any null values and replace with centrel tendancy provided by user \n",
    "        ===========================================================================================\n",
    "        Input : \n",
    "            df --> original Data \n",
    "            cd --> Centrel tendancy -- mean,mode,median\n",
    "            \n",
    "        Output :\n",
    "            df --> Data without null values \n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "        \n",
    "            if cd == mean : \n",
    "\n",
    "                for i in range(df.shape[1]): \n",
    "                    if df.isnull().sum()[i] >0: \n",
    "\n",
    "                        df[\"{}\".format(df.isnull().sum().index[i])] = df[\"{}\".format(df.isnull().sum().index[i])].fillna(df[\"{}\".format(df.isnull().sum().index[i])].mean()) \n",
    "                        return df \n",
    "                    \n",
    "            elif cd == mode : \n",
    "                for i in range(df.shape[1]): \n",
    "                    if df.isnull().sum()[i] >0: \n",
    "                        df[\"{}\".format(df.isnull().sum().index[i])] = df[\"{}\".format(df.isnull().sum().index[i])].fillna(df[\"{}\".format(df.isnull().sum().index[i])].mode()) \n",
    "                        return df \n",
    "                    \n",
    "            elif cd == median : \n",
    "                for i in range(df.shape[1]): \n",
    "                    if df.isnull().sum()[i] >0: \n",
    "                        df[\"{}\".format(df.isnull().sum().index[i])] = df[\"{}\".format(df.isnull().sum().index[i])].fillna(df[\"{}\".format(df.isnull().sum().index[i])].median()) \n",
    "                         return df \n",
    "                        \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(remove_null_val) - failed to remove null values.\\n\" + str(e))\n",
    "            \n",
    "    ###### Now Linear Regression #######\n",
    "    \n",
    "    def predic_feature_col_split(self,df,pred_col): \n",
    "        \"\"\"This function returns prediction column and feature columns\n",
    "        ===============================================\n",
    "        Inputs : \n",
    "            df --> Data \n",
    "            pred_col --> Prediction Column name \n",
    "        Output : \n",
    "            x --> feature columns\n",
    "            y --> prediction column \n",
    "        \"\"\"\n",
    "        try : \n",
    "            y = df[pred_col]\n",
    "            x = df.drop(columns=[pred_col])\n",
    "            \n",
    "            return x,y \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(predic_feature_col_split) - failed to split data into prediction and feature columns.\\n\" + str(e))\n",
    "            \n",
    "    def Standardizing_dataset(self,df,pred_col): \n",
    "        \n",
    "        \"\"\"This function return Standardized dataset containing only feature columns\n",
    "        ==============================================================================\n",
    "        Input : \n",
    "            df --> Data with prediction column\n",
    "            pred_col--> prediction column name \n",
    "        Output : \n",
    "            df2 --> Standardise dataset with only feature columns and no prediction column \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            x,y = predic_feature_col_split(df,pred_col)\n",
    "            scaler = StandardScaler()\n",
    "            arr1 = scaler.fit_transform(x)\n",
    "            df2 = pd.DataFrame(arr1,columns=x.columns)\n",
    "            return df2 \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(Standardizing_dataset) - failed to standardize dataset.\\n\" + str(e))\n",
    "            \n",
    "    def VIF(self,df,pred_col): \n",
    "        \n",
    "        \"\"\"This function creates a dataframe containing VIF of given data\n",
    "        ============================================================================\n",
    "        Input : \n",
    "            df --> data with prediction column\n",
    "            \n",
    "        Output : \n",
    "            df_vif --> dataframe containing VIF of all features\n",
    "        \"\"\"\n",
    "        try : \n",
    "            df1 = Standardizing_dataset(df,pred_col)\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            df_vif = pd.DataFrame()\n",
    "            df_vif[\"Features\"] = df1.columns\n",
    "            df_vif[\"VIF\"] = [variance_inflation_factor(df1,i) for i in range(df1.shape[1])]\n",
    "\n",
    "            return df_vif \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(VIF)- failed to find VIF of data.\\n\" + str(e))\n",
    "            \n",
    "    def give_high_VIF_col(self,df,pred_col): \n",
    "        from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "        \"\"\" This function provides name of columns which has high variance inflation factor\n",
    "        ============================================================================\n",
    "        Input : \n",
    "            df --> Data with prediction column \n",
    "            pred_col --> Prediction column name \n",
    "            \n",
    "        Output : \n",
    "            l --> List containing names of columns which has VIF > 10 \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            df_vif = VIF(df,pred_col)\n",
    "            l = []\n",
    "            for i in range(df_vif.shape[0]): \n",
    "                if df_vif.iloc[i,1] > 10 : \n",
    "                    l.append(df_vif.iloc[i,0])\n",
    "            return l \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(give_high_VIF_col)-failed to provide high VIF column names\")\n",
    "            \n",
    "            \n",
    "    def training_dataset(self,df,pred_col,test_size): \n",
    "        \"\"\"This function create a seperate training dataset with standardizing the dataset\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            test_size --> size of test-train split \n",
    "            random state = 100 \n",
    "        output : \n",
    "            train_x --> x training data \n",
    "            train_y --> y training data \n",
    "        \n",
    "        \"\"\"\n",
    "        try : \n",
    "            x,y = predic_feature_col_split(df,pred_col)\n",
    "            df2 = Standardizing_dataset(df,pred_col)\n",
    "            x_train,x_test,y_train,y_test = train_test_split(df2,y,test_size=test_size,random_state=100)\n",
    "            return x_train,y_train\n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(training_dataset)-failed to find training dataset.\\n\" + str(e))\n",
    "            \n",
    "    def testing_dataset(self,df,pred_col,test_size): \n",
    "        \"\"\"This function create a seperate testing dataset with standardizing the dataset\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "        output : \n",
    "            train_x --> x training data \n",
    "            train_y --> y training data \n",
    "            test ataset --> test train split size \n",
    "        \n",
    "        \"\"\"\n",
    "        try : \n",
    "            x,y = predic_feature_col_split(df,pred_col)\n",
    "            df2 = Standardizing_dataset(df,pred_col)\n",
    "            x_train,x_test,y_train,y_test = train_test_split(df2,y,test_size=test_size,random_state=100)\n",
    "            return x_test,y_test\n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(testing_dataset)-failed to find testing dataset.\\n\" + str(e))\n",
    "    \n",
    "        \n",
    "            \n",
    "    def fit_LinearRegression(self,df,pred_col,test_size): \n",
    "        \"\"\"This function fit Linear regression model \n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "        output : \n",
    "            linear = Linear regression fitted model \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            x,y = predic_feature_col_split(df,pred_col)\n",
    "            df2 = Standardizing_dataset(df,pred_col)\n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            linear = LinearRegression()\n",
    "            linear.fit(x_train,y_train)\n",
    "            return linear \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(fit_LinearRegression) - failed to fit the model.\\n\" + str(e))\n",
    "            \n",
    "    def r2_linear(self,df,pred_col,test_size): \n",
    "        \"\"\"This function find r2 of  Linear regression model \n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "        output : \n",
    "            r2_lin = r2 value of linear model \n",
    "        \"\"\"\n",
    "        try : \n",
    "            linear =  fit_LinearRegression(df,pred_col=pred_col,test_size=test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            r2_lin = linear.score(x_test,y_test)\n",
    "            return r2_lin \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(r2_linear) - failed to find r2 value of linear model\")\n",
    "            \n",
    "    def adj_r2(self,df,pred_col,test_size): \n",
    "        \"\"\"This function find adjusted r2 of  Linear regression model \n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "        output : \n",
    "            adjusted_r2 = adjusted r2 value of linear model \n",
    "        \"\"\"\n",
    "        try : \n",
    "            x,y = predic_feature_col_split(df,pred_col)\n",
    "            n = x.shape[0]\n",
    "            p = x.shape[1]\n",
    "            fit_LinearRegression(df,pred_col,test_size) \n",
    "            r2 = linear.score(x,y)\n",
    "            adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "            return adjusted_r2\n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(adj_r2) -- failed to find adjusted r2.\\n\" + str(e))\n",
    "            \n",
    "            \n",
    "    def lasso_alpha(self,df,pred_col,test_size): \n",
    "        \"\"\"This function does cross validation with dataset and finds out alpha value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "            max_iter = 2000000\n",
    "            \n",
    "        output : \n",
    "            alpha = regularizing coefficient  \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            lassocv = LassoCV(alphas=None,max_iter=2000000,normalize=True)\n",
    "            lassocv.fit(x_train,y_train)\n",
    "            alpha = lassocv.alpha_\n",
    "            return alpha \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(lasso_alpha) - falied to find out alpha value \")\n",
    "            \n",
    "            \n",
    "    def r2_lasso(self,df,pred_col,test_size): \n",
    "        \"\"\"This function  finds out lasso r2 value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "           \n",
    "            \n",
    "        output : \n",
    "            r2_lass = lasso r2 value   \n",
    "        \"\"\"\n",
    "        try : \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            alpha = lasso_alpha(self,df,pred_col,test_size)\n",
    "            lasso = Lasso(alpha=alpha)\n",
    "            lasso.fit(x_train,y_train)\n",
    "            r2_lass = lasso.score(x_test,y_test)\n",
    "            return r2_lass \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(r2-lasso) - failed to find out lasso r2 value.\\n\" + str(e))\n",
    "            \n",
    "            \n",
    "    def ridge_alpha(self,df,pred_col,test_size): \n",
    "        \"\"\"This function  finds out ridge alpha value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "            cv=10\n",
    "            \n",
    "           \n",
    "        output : \n",
    "            alpha = Ridge alpha value    \n",
    "        \"\"\"\n",
    "        try : \n",
    "            \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            ridgecv = RidgeCV(alphas=np.random.uniform(1,10,50),cv=10,normalize=True)\n",
    "            ridgecv.fit(x_train,y_train)\n",
    "            alpha = ridgecv.alpha_\n",
    "            return alpha \n",
    "        \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(ridge_alpha) - failed to find out ridge alpha value.\\n\" + str(e))\n",
    "            \n",
    "    def r2_ridge(self,df,pred_col,test_size): \n",
    "        \"\"\"This function  finds out ridge r2 value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "            cv=10\n",
    "            \n",
    "           \n",
    "        output : \n",
    "            r2_rid = ridge r2 value   \n",
    "        \"\"\"\n",
    "        try : \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            alpha = ridge_alpha(df,pred_col,test_size) \n",
    "            ridge = Ridge(alpha=alpha)\n",
    "            ridge.fit(x_train,y_train)\n",
    "            r2_rid = ridge.score(x_test,y_test)\n",
    "            return r2_rid \n",
    "        \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(r2_ridge) - failed to find out ridge r2 value.\\n\" + str(e))\n",
    "            \n",
    "        \n",
    "    def elastic_net_alpha(self,df,pred_col,test_size): \n",
    "        \"\"\"This function  finds out elastic net alpha  value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "            cv=10\n",
    "            \n",
    "           \n",
    "        output : \n",
    "            alpha = elastic net alpha value   \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            elasticnetcv = ElasticNetCV(alphas=None,cv = 10)\n",
    "            elasticnetcv.fit(x_train,y_train)\n",
    "            alpha = elasticnetcv.alpha_\n",
    "            return alpha \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(elastic_net_alpha) - failed to find elastic net alpha value.\\n\" + str(e))\n",
    "            \n",
    "    \n",
    "    \n",
    "    def elastic_net_l1_ratio(self,df,pred_col,test_size): \n",
    "        \"\"\"This function  finds out elastic net alpha  value\n",
    "        ========================================================================================\n",
    "        ****IMPORTANT - standardization is used here \n",
    "        Input : \n",
    "            df --> Data without prediction column \n",
    "            pred_col --> prediction column name \n",
    "            random state = 100 \n",
    "            test_size = test train split size \n",
    "            cv=10\n",
    "            \n",
    "           \n",
    "        output : \n",
    "            l1_ratio = elastic net l1_ratio  \n",
    "        \"\"\"\n",
    "        \n",
    "        try : \n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            elasticnetcv = ElasticNetCV(alphas=None,cv = 10)\n",
    "            elasticnetcv.fit(x_train,y_train)\n",
    "            l1_ratio = elasticnetcv.l1_ratio_\n",
    "            return l1_ratio \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(elastic_net_l1_ratio) - failed to find elastic net l1 ratio .\\n\" + str(e))\n",
    "            \n",
    "    def r2_elastic_net(self,df,pred_col,test_size): \n",
    "        \n",
    "        \n",
    "        try : \n",
    "            alpha = elastic_net_alpha(df,pred_col,test_size)\n",
    "            l1_ratio = elastic_net_l1_ratio(self,df,pred_col,test_size)\n",
    "            x_train,y_train = training_dataset(df,pred_col,test_size)\n",
    "            x_test,y_test = testing_dataset(df,pred_col,test_size)\n",
    "            elasticnet = ElasticNet(alpha=alpha,l1_ratio=l1_ratio_)\n",
    "            elasticnet.fit(x_train,y_train)\n",
    "            r2_elastic = elasticnet.score(x_test,y_test)\n",
    "            return r2_elastic \n",
    "        except Exception as e : \n",
    "            raise Exception(f\"(r2_elastic_net)- failed to find out elastic net r2 value\")\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "668c0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(): \n",
    "    try : \n",
    "        a = 10 \n",
    "        b = \"vina\" \n",
    "        result = a/b \n",
    "        return result\n",
    "\n",
    "    except Exception as e :\n",
    "        raise (Exception(f\" - Type Error\\n\" + str(e))) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1746d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(a,b): \n",
    "    return a/b\n",
    "\n",
    "add(b=2,a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c7069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f884aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6990b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e82892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c638b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
